# A directory For all the produced outputs
artifacts_root: artifacts

data_ingestion:
  root_dir: artifacts/data_ingestion
  data_folder_path: artifacts/data_ingestion
  AWS_BUCKET_NAME: samyarsworld-nucleidata
  AWS_DATASET_NAME: data.zip

data_validation:
  root_dir: artifacts/data_validation
  data_path: artifacts/data_ingestion/data
  required_files: ["train", "test"]
  status_path: artifacts/data_validation/status.txt

data_construction:
  root_dir: artifacts/data_construction
  train_path: artifacts/data_ingestion/data/train
  h_params:
    TRAIN_SIZE: 0.7
    IMG_WIDTH: 128
    IMG_HEIGHT: 128
    BATCH_SIZE: 32

model_trainer:
  root_dir: artifacts/model_trainers
  algorithm_name: UNET
  IMG_CHANNELS: 3
  MASK_CHANNELS: 1
  # pre_trained_model: url
  # pre_trained_model_path: artifacts/model_trainers/UNET/pre_trained_model.pt
  model_path: artifacts/model_trainers/UNET/model.pt

  # Hyper parameters
  h_params:
    epochs: 20
    lr: 0.01
    channels: [16, 32, 64, 128, 256]
    # warmup_steps: 500
    # logging_steps: 10
    # eval_steps: 500
    # save_steps: 1000000

model_evaluation:
  root_dir: artifacts/model_evaluation
  model_path: artifacts/model_trainers/UNET/model.pt
  metric_file_name: artifacts/model_evaluation/metrics.csv
  params:
    eval_batch_size: 2
    n_samples: 10

target_prediction:
  root_dir: artifacts/target_prediction
  model_path: artifacts/model_trainers/UNET/model.pt
  test_path: artifacts/data_ingestion/data/test
  IMG_WIDTH: 128
  IMG_HEIGHT: 128
  channels: [16, 32, 64, 128, 256]
